# Solving AI with a deeply convoluted and nervous network

## Abstract

##Modification made by Liyuan
A paper about DCNNs has been requested by our phD overlords
We propose a novel approach to build an amazing AI using the so called DCNNs. This is the best network ever!

## Introduction
We propose to use convolutions instead of fully connected  networks because convolutions are awesome! 

## Background
Notions in algebraic topology and metric measure spaces. 
Random edit to test conflicts

## Convoluted layers increase excitation of nervous networks


## One equation to rule them all
 
     $\theta_{k+1} = \theta_k - \gamma \nabla L(\theta_k) $

## Various tricks
### Learning rate
We use cross-validation
### Early stopping
Stop when the network best fits the validation set
### Gradient clipping
Avoid exploiding gradients
### Drop-out
### Weight decay

### Batch normalization
### Etc,...


## Conclusion
We are trying to do stuff in git.  
In conclusion, ![shiba](shiba.jpg)
